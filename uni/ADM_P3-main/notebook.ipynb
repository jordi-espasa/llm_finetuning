{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel, AutoTokenizer\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import evaluate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 174M/174M [00:02<00:00, 66.8MB/s] \n",
      "Downloading data: 100%|██████████| 17.0M/17.0M [00:01<00:00, 14.1MB/s]\n",
      "Downloading data: 100%|██████████| 180M/180M [00:02<00:00, 87.0MB/s] \n",
      "Downloading data: 100%|██████████| 176M/176M [00:02<00:00, 81.6MB/s] \n",
      "Downloading data: 100%|██████████| 83.4M/83.4M [00:01<00:00, 79.9MB/s]\n",
      "Generating train split: 100%|██████████| 2753/2753 [00:00<00:00, 4129.46 examples/s]\n",
      "Generating test split: 100%|██████████| 6085/6085 [00:01<00:00, 4490.00 examples/s]\n",
      "Downloading data: 100%|██████████| 971/971 [00:00<00:00, 7.42kB/s]\n",
      "Generating train split: 102 examples [00:00, 105374.14 examples/s]\n",
      "Downloading data: 100%|██████████| 646/646 [00:00<00:00, 4.29kB/s]\n",
      "Generating train split: 34 examples [00:00, 18245.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = load_dataset(\"clip-benchmark/wds_vtab-caltech101\")\n",
    "classes = load_dataset(\"clip-benchmark/wds_vtab-caltech101\", data_files=\"classnames.txt\")[\"train\"][\"text\"]\n",
    "templates = load_dataset(\"clip-benchmark/wds_vtab-caltech101\", data_files=\"zeroshot_classification_templates.txt\")[\"train\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_dict[\"train\"] #concatenate_datasets([dataset_dict[\"train\"], dataset_dict[\"test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = [\n",
    "    \"openai/clip-vit-base-patch16\",\n",
    "    \"openai/clip-vit-base-patch32\",\n",
    "    \"openai/clip-vit-large-patch14\",\n",
    "    \"openai/clip-vit-large-patch14-336\",\n",
    "][0]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CLIPModel.from_pretrained(model_id)\n",
    "model.to(device)\n",
    "processor = CLIPProcessor.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baseline\n",
    "# inputs = tokenizer(classes, padding=True, return_tensors=\"pt\")\n",
    "# inputs = {k: t.to(model.device) for k, t in inputs.items()}\n",
    "# with torch.no_grad():\n",
    "#     text_features = model.get_text_features(**inputs)\n",
    "# def zero_shot_classify(images, text_features):\n",
    "#     inputs = processor(images=images, return_tensors=\"pt\")\n",
    "#     inputs = {k: t.to(model.device) for k, t in inputs.items()}\n",
    "#     with torch.no_grad():\n",
    "#         image_features = model.get_image_features(**inputs)\n",
    "\n",
    "#     # Softmax with temperature\n",
    "#     image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)\n",
    "#     text_features = text_features / text_features.norm(p=2, dim=-1, keepdim=True)\n",
    "#     logits = 100.0 * (image_features @ text_features.t())\n",
    "#     probs = logits.softmax(dim=1)\n",
    "#     pred = pred.argmax(dim=1)\n",
    "#     return pred\n",
    "\n",
    "# # With ensemble mean\n",
    "# text_features = []\n",
    "# for name in classes:\n",
    "#     name_templates = [template.format(c=name) for template in templates]\n",
    "#     inputs = tokenizer(name_templates, padding=True, return_tensors=\"pt\")\n",
    "#     inputs = {k: t.to(model.device) for k, t in inputs.items()}\n",
    "#     with torch.no_grad():\n",
    "#         name_text_features = model.get_text_features(**inputs)\n",
    "#     avg_text_features = name_text_features.mean(0)\n",
    "#     text_features.append(avg_text_features)\n",
    "# text_features = torch.stack(text_features)\n",
    "\n",
    "# def zero_shot_classify(images, text_features):\n",
    "#     inputs = processor(images=images, return_tensors=\"pt\")\n",
    "#     inputs = {k: t.to(model.device) for k, t in inputs.items()}\n",
    "#     with torch.no_grad():\n",
    "#         image_features = model.get_image_features(**inputs)\n",
    "\n",
    "#     # Softmax with temperature\n",
    "#     image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)\n",
    "#     text_features = text_features / text_features.norm(p=2, dim=-1, keepdim=True)\n",
    "#     logits = 100.0 * (image_features @ text_features.t())\n",
    "#     # probs = logits.softmax(dim=1)\n",
    "#     pred = logits.argmax(dim=1)\n",
    "#     return pred\n",
    "\n",
    "# With ensemble\n",
    "ensemble_method = \"mean_logit\" # \"mean_logit\", \"mean_softmax\"\n",
    "text_features = []\n",
    "for name in classes:\n",
    "    name_templates = [template.format(c=name) for template in templates]\n",
    "    inputs = tokenizer(name_templates, padding=True, return_tensors=\"pt\")\n",
    "    inputs = {k: t.to(model.device) for k, t in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        name_text_features = model.get_text_features(**inputs)\n",
    "    text_features.append(name_text_features)\n",
    "text_features = torch.stack(text_features)\n",
    "\n",
    "def zero_shot_classify(images, text_features):\n",
    "    inputs = processor(images=images, return_tensors=\"pt\")\n",
    "    inputs = {k: t.to(model.device) for k, t in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        image_features = model.get_image_features(**inputs)\n",
    "    \n",
    "    s = text_features.shape\n",
    "    text_features_view = text_features.view((s[0] * s[1], s[2]))\n",
    "\n",
    "    # Softmax with temperature\n",
    "    image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)\n",
    "    text_features_view = text_features_view / text_features_view.norm(p=2, dim=-1, keepdim=True)\n",
    "    logits = 100.0 * (image_features @ text_features_view.t())\n",
    "\n",
    "    logits = logits.view((logits.shape[0], s[0], s[1]))\n",
    "\n",
    "    if ensemble_method == \"mean_logit\":\n",
    "        probs = logits.mean(-1).softmax(dim=1)\n",
    "    else:\n",
    "        probs = logits.softmax(dim=1).mean(-1)\n",
    "\n",
    "    pred = probs.argmax(dim=1)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 2.57MB/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'ExifTags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# .select(range(100))\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39miter(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m):\n\u001b[1;32m      5\u001b[0m     pred \u001b[38;5;241m=\u001b[39m zero_shot_classify(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwebp\u001b[39m\u001b[38;5;124m\"\u001b[39m], text_features)\n\u001b[1;32m      6\u001b[0m     accuracy\u001b[38;5;241m.\u001b[39madd_batch(references\u001b[38;5;241m=\u001b[39msample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m], predictions\u001b[38;5;241m=\u001b[39mpred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:2476\u001b[0m, in \u001b[0;36mDataset.iter\u001b[0;34m(self, batch_size, drop_last_batch)\u001b[0m\n\u001b[1;32m   2474\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m get_formatter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2475\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pa_subtable \u001b[38;5;129;01min\u001b[39;00m table_iter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch):\n\u001b[0;32m-> 2476\u001b[0m         formatted_batch \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2477\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2478\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2479\u001b[0m \u001b[43m            \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[43m            \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2481\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_all_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2483\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m formatted_batch\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:633\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    631\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:401\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:450\u001b[0m, in \u001b[0;36mPythonFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyBatch(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    449\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[0;32m--> 450\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:222\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m batch\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/features/features.py:2029\u001b[0m, in \u001b[0;36mFeatures.decode_batch\u001b[0;34m(self, batch, token_per_repo_id)\u001b[0m\n\u001b[1;32m   2026\u001b[0m decoded_batch \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_name, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2028\u001b[0m     decoded_batch[column_name] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 2029\u001b[0m         [\n\u001b[1;32m   2030\u001b[0m             decode_nested_example(\u001b[38;5;28mself\u001b[39m[column_name], value, token_per_repo_id\u001b[38;5;241m=\u001b[39mtoken_per_repo_id)\n\u001b[1;32m   2031\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2033\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m column\n\u001b[1;32m   2034\u001b[0m         ]\n\u001b[1;32m   2035\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   2036\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m column\n\u001b[1;32m   2037\u001b[0m     )\n\u001b[1;32m   2038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decoded_batch\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/features/features.py:2030\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2026\u001b[0m decoded_batch \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_name, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2028\u001b[0m     decoded_batch[column_name] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2029\u001b[0m         [\n\u001b[0;32m-> 2030\u001b[0m             \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2031\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2033\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m column\n\u001b[1;32m   2034\u001b[0m         ]\n\u001b[1;32m   2035\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   2036\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m column\n\u001b[1;32m   2037\u001b[0m     )\n\u001b[1;32m   2038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decoded_batch\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/features/features.py:1351\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (Audio, Image)):\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mdecode:\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/features/image.py:189\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    187\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[1;32m    188\u001b[0m image\u001b[38;5;241m.\u001b[39mload()  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(\u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExifTags\u001b[49m\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m image\u001b[38;5;241m.\u001b[39mmode:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:65\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories are deprecated and will be removed in Pillow 10 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(2023-07-01). Use is_animated instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     63\u001b[0m     )\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m categories[name]\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'ExifTags'"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "# .select(range(100))\n",
    "for sample in dataset.iter(batch_size=64):\n",
    "    pred = zero_shot_classify(sample[\"webp\"], text_features)\n",
    "    accuracy.add_batch(references=sample[\"cls\"], predictions=pred)\n",
    "\n",
    "accuracy.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds-adm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
